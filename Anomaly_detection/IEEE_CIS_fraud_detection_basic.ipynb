{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IEEE-CIS fraud detection_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1m5zqNKX1kBWTK_DI5Fcsp0OJNQ5RuP9j",
      "authorship_tag": "ABX9TyNDgh0yKfUBGWDeaioQyZu2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/upperai0510/project_team/blob/sejin/Anomaly_detection/IEEE_CIS_fraud_detection_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRdpGyK0EKN6"
      },
      "source": [
        "# 사기 감지 (fraud detection)\r\n",
        "\r\n",
        "anomaly detection\r\n",
        "\r\n",
        "데이터로부터 p(x) 를 만들어, 검사할 데이터가 threshold 를 넘는지 안넘는지 검사해 anomaly 로 판정할 수 있다.\r\n",
        "\r\n",
        "참고로, anomaly 가 너무 많으면, false positive 가 높은 것인데 이 때는 threshold 를 줄이면 된다.\r\n",
        "\r\n",
        "Categorical Features - Transaction\r\n",
        "\r\n",
        "- ProductCD\r\n",
        "-emaildomain\r\n",
        "-card1 - card6\r\n",
        "-addr1, addr2\r\n",
        "-P_emaildomain\r\n",
        "-R_emaildomain\r\n",
        "-M1 - M9\r\n",
        "\r\n",
        "Categorical Features - Identity\r\n",
        "\r\n",
        "- DeviceType\r\n",
        "-DeviceInfo\r\n",
        "-id_12 - id_38"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAYjH_ZuCS7f",
        "outputId": "55573de0-e3b6-4152-9792-8edfe8a53ba9"
      },
      "source": [
        "! cp /content/drive/MyDrive/kaggle/kaggle.json /root/.kaggle/\r\n",
        "! kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4bFsiHBSLsH"
      },
      "source": [
        "# ! git clone --recursive https://github.com/Microsoft/LightGBM\r\n",
        "# ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z7gLJBxCtec"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from sklearn import preprocessing\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lpuxf13DBfd"
      },
      "source": [
        "train_transaction = pd.read_csv('/content/train_transaction.csv.zip', index_col='TransactionID')\r\n",
        "test_transaction = pd.read_csv('/content/test_transaction.csv.zip', index_col='TransactionID')\r\n",
        "\r\n",
        "train_identity = pd.read_csv('/content/train_identity.csv.zip', index_col='TransactionID')\r\n",
        "test_identity = pd.read_csv('/content/test_identity.csv.zip', index_col='TransactionID')\r\n",
        "\r\n",
        "sample_submission = pd.read_csv('/content/sample_submission.csv.zip', index_col='TransactionID')\r\n",
        "\r\n",
        "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\r\n",
        "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\r\n",
        "\r\n",
        "y_train = train['isFraud'].copy()\r\n",
        "del train_transaction, train_identity, test_transaction, test_identity\r\n",
        "\r\n",
        "# Drop target, fill in NaNs\r\n",
        "X_train = train.drop('isFraud', axis=1)\r\n",
        "X_test = test.copy()\r\n",
        "\r\n",
        "del train, test"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd5wo1JXEWaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fde833-232d-439e-b091-051668b33d5c"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    569877\n",
              "1     20663\n",
              "Name: isFraud, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBKoLlnOEjCU"
      },
      "source": [
        "train target = binary 형태\r\n",
        "\r\n",
        "test target = roc curve 확률"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFJAdK6wPdO9"
      },
      "source": [
        "X_test=X_test.rename(columns={'id-01':'id_01','id-02':'id_02','id-03':'id_03','id-04':'id_04','id-05':'id_05',\r\n",
        "                         'id-06':'id_06','id-07':'id_07','id-08':'id_08','id-09':'id_09',\r\n",
        "                         'id-10':'id_10','id-11':'id_11','id-12':'id_12','id-13':'id_13','id-14':'id_14',\r\n",
        "                         'id-15':'id_15','id-16':'id_16','id-17':'id_17','id-18':'id_18','id-19':'id_19',\r\n",
        "                         'id-20':'id_20','id-21':'id_21','id-22':'id_22','id-23':'id_23','id-24':'id_24',\r\n",
        "                         'id-25':'id_25','id-26':'id_26','id-27':'id_27','id-28':'id_28','id-29':'id_29',\r\n",
        "                         'id-30':'id_30','id-31':'id_31','id-32':'id_32','id-33':'id_33','id-34':'id_34',\r\n",
        "                         'id-35':'id_35','id-36':'id_36','id-37':'id_37','id-38':'id_38'})"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o9peZceNOP4"
      },
      "source": [
        "# 데이터 프레임 데이터 타입을 바꿈으로써 전체적인 데이터 사용량을 줄임\r\n",
        "\r\n",
        "def reduce_mem_usage(df, verbose=True):\r\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\r\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \r\n",
        "    for col in df.columns:\r\n",
        "        col_type = df[col].dtypes\r\n",
        "        if col_type in numerics:\r\n",
        "            c_min = df[col].min()\r\n",
        "            c_max = df[col].max()\r\n",
        "            if str(col_type)[:3] == 'int':\r\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\r\n",
        "                    df[col] = df[col].astype(np.int8)\r\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\r\n",
        "                    df[col] = df[col].astype(np.int16)\r\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\r\n",
        "                    df[col] = df[col].astype(np.int32)\r\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\r\n",
        "                    df[col] = df[col].astype(np.int64)  \r\n",
        "            else:\r\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\r\n",
        "                    df[col] = df[col].astype(np.float16)\r\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\r\n",
        "                    df[col] = df[col].astype(np.float32)\r\n",
        "                else:\r\n",
        "                    df[col] = df[col].astype(np.float64)    \r\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\r\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\r\n",
        "    return df"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-laGrCUeM6KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8d1727-1eef-4a1a-9aab-89ba991f7344"
      },
      "source": [
        "## REducing memory\r\n",
        "X_train = reduce_mem_usage(X_train)\r\n",
        "X_test = reduce_mem_usage(X_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 667.66 Mb (66.1% reduction)\n",
            "Mem. usage decreased to 583.43 Mb (65.6% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I1lhcnGT4ve"
      },
      "source": [
        "# fill in NaNs\r\n",
        "for c in X_train.columns:\r\n",
        "    if X_train[c].dtype=='float16' or  X_train[c].dtype=='float32' or  X_train[c].dtype=='float64':\r\n",
        "        X_train[c].fillna(X_train[c].mean())\r\n",
        "        X_test[c].fillna(X_train[c].mean())\r\n",
        "\r\n",
        "X_train = X_train.fillna(-999)\r\n",
        "X_test = X_test.fillna(-999)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzXsuEHlSNLc"
      },
      "source": [
        "# Label Encoding\r\n",
        "for f in X_train.columns:\r\n",
        "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \r\n",
        "        lbl = preprocessing.LabelEncoder()\r\n",
        "        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\r\n",
        "        X_train[f] = lbl.transform(list(X_train[f].values))\r\n",
        "        X_test[f] = lbl.transform(list(X_test[f].values))  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XbPmdJlWyZG",
        "outputId": "87324fc0-0f11-43c0-b4ca-89bbdfa6e2f2"
      },
      "source": [
        "!pip install bayesian-optimization"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz1BxwJuS81I",
        "outputId": "843c679c-c793-4eac-bb9d-7d4bc7b7e107"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\r\n",
        "from bayes_opt import BayesianOptimization\r\n",
        "import xgboost as xgb\r\n",
        "        \r\n",
        "X = X_train\r\n",
        "y = y_train\r\n",
        "\r\n",
        "def XGB_cv(max_depth, gamma, colsample_bytree, min_child_weight):\r\n",
        "    \r\n",
        "    model = xgb.XGBClassifier(\r\n",
        "                              use_label_encoder=False,\r\n",
        "                              tree_method = 'gpu_hist',\r\n",
        "                              predictor = 'gpu_predictor',\r\n",
        "                              metric= 'auc',\r\n",
        "\r\n",
        "                              max_depth = int(max_depth),   \r\n",
        "                              gamma=gamma,\r\n",
        "                              colsample_bytree=colsample_bytree,\r\n",
        "                              min_child_weight = int(min_child_weight))\r\n",
        "    \r\n",
        "    cval = cross_val_score(model, X, y, scoring='roc_auc', cv=5).mean()\r\n",
        "    return cval\r\n",
        "\r\n",
        "# 주어진 범위 사이에서 적절한 값을 찾는다.\r\n",
        "pbounds={\r\n",
        "    'max_depth': (7,14),\r\n",
        "    'gamma': (0, 1),\r\n",
        "    'colsample_bytree': (0.5, 1.0),\r\n",
        "    'min_child_weight' : (1, 3)      \r\n",
        "}\r\n",
        "\r\n",
        "xgboostBO = BayesianOptimization(f = XGB_cv,pbounds = pbounds, verbose = 2, random_state = 1 )\r\n",
        "\r\n",
        "xgboostBO.maximize(init_points=10, n_iter = 10)\r\n",
        "# n_iter : 수행하려는 베이지안 최적화 단계. 더 많은 단계를 거치면 더 좋은 최대치 얻음\r\n",
        "# init_points : 수행할 무작위 탐색 단계\r\n",
        "\r\n",
        "print(xgboostBO.max) # 찾은 파라미터 값 확인\r\n",
        "\r\n",
        "fit_xgb = xgb.XGBClassifier(\r\n",
        "                            max_depth= int(xgboostBO.max['params']['max_depth'] ),\r\n",
        "                            gamma= xgboostBO.max['params']['gamma'],\r\n",
        "                            colsample_bytree=xgboostBO.max['params']['colsample_bytree'],\r\n",
        "                            min_child_weight = int(xgboostBO.max['params']['min_child_weight']),\r\n",
        "\r\n",
        "                            metric= 'auc',\r\n",
        "                            use_label_encoder=False,\r\n",
        "                            tree_method = 'gpu_hist',\r\n",
        "                            predictor = 'gpu_predictor')\r\n",
        "\r\n",
        "\r\n",
        "model  = fit_xgb.fit(X, y)\r\n",
        "pred_xgb = model.predict_proba(X_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8777  \u001b[0m | \u001b[0m 0.7085  \u001b[0m | \u001b[0m 0.7203  \u001b[0m | \u001b[0m 7.001   \u001b[0m | \u001b[0m 1.605   \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8789  \u001b[0m | \u001b[95m 0.5734  \u001b[0m | \u001b[95m 0.09234 \u001b[0m | \u001b[95m 7.931   \u001b[0m | \u001b[95m 1.691   \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8889  \u001b[0m | \u001b[95m 0.6984  \u001b[0m | \u001b[95m 0.5388  \u001b[0m | \u001b[95m 9.096   \u001b[0m | \u001b[95m 2.37    \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8788  \u001b[0m | \u001b[0m 0.6022  \u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 7.137   \u001b[0m | \u001b[0m 2.341   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8777  \u001b[0m | \u001b[0m 0.7087  \u001b[0m | \u001b[0m 0.5587  \u001b[0m | \u001b[0m 7.702   \u001b[0m | \u001b[0m 1.396   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 0.9004  \u001b[0m | \u001b[0m 0.9683  \u001b[0m | \u001b[0m 8.567   \u001b[0m | \u001b[0m 2.385   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8751  \u001b[0m | \u001b[0m 0.9382  \u001b[0m | \u001b[0m 0.8946  \u001b[0m | \u001b[0m 7.425   \u001b[0m | \u001b[0m 1.078   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.5849  \u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 7.492   \u001b[0m | \u001b[0m 1.842   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8769  \u001b[0m | \u001b[0m 0.9789  \u001b[0m | \u001b[0m 0.5332  \u001b[0m | \u001b[0m 10.46   \u001b[0m | \u001b[0m 1.631   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8735  \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.8346  \u001b[0m | \u001b[0m 7.091   \u001b[0m | \u001b[0m 2.5     \u001b[0m |\n",
            "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.8969  \u001b[0m | \u001b[95m 0.6018  \u001b[0m | \u001b[95m 0.9192  \u001b[0m | \u001b[95m 11.93   \u001b[0m | \u001b[95m 2.969   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8966  \u001b[0m | \u001b[0m 0.634   \u001b[0m | \u001b[0m 0.007457\u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 2.944   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8939  \u001b[0m | \u001b[0m 0.5059  \u001b[0m | \u001b[0m 0.7826  \u001b[0m | \u001b[0m 10.84   \u001b[0m | \u001b[0m 2.985   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8728  \u001b[0m | \u001b[0m 0.9967  \u001b[0m | \u001b[0m 0.2874  \u001b[0m | \u001b[0m 11.98   \u001b[0m | \u001b[0m 2.978   \u001b[0m |\n",
            "| \u001b[95m 15      \u001b[0m | \u001b[95m 0.897   \u001b[0m | \u001b[95m 0.511   \u001b[0m | \u001b[95m 0.002706\u001b[0m | \u001b[95m 11.92   \u001b[0m | \u001b[95m 1.015   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.896   \u001b[0m | \u001b[0m 0.5291  \u001b[0m | \u001b[0m 0.8808  \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 1.049   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8957  \u001b[0m | \u001b[0m 0.5081  \u001b[0m | \u001b[0m 0.3823  \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 2.1     \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8917  \u001b[0m | \u001b[0m 0.5314  \u001b[0m | \u001b[0m 0.8921  \u001b[0m | \u001b[0m 9.84    \u001b[0m | \u001b[0m 1.04    \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8909  \u001b[0m | \u001b[0m 0.5047  \u001b[0m | \u001b[0m 0.04037 \u001b[0m | \u001b[0m 9.552   \u001b[0m | \u001b[0m 2.981   \u001b[0m |\n",
            "| \u001b[95m 20      \u001b[0m | \u001b[95m 0.8982  \u001b[0m | \u001b[95m 0.5363  \u001b[0m | \u001b[95m 0.2409  \u001b[0m | \u001b[95m 11.91   \u001b[0m | \u001b[95m 2.947   \u001b[0m |\n",
            "=========================================================================\n",
            "{'target': 0.8981908463624638, 'params': {'colsample_bytree': 0.5363034369458757, 'gamma': 0.2408675804291115, 'max_depth': 11.907038563899869, 'min_child_weight': 2.947400143249704}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6FyT3wg5a87",
        "outputId": "91d26904-8baa-4369-c79d-a409f94a1588"
      },
      "source": [
        "model.get_params"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=0.5363034369458757,\n",
              "              gamma=0.2408675804291115, learning_rate=0.1, max_delta_step=0,\n",
              "              max_depth=11, metric='auc', min_child_weight=2, missing=None,\n",
              "              n_estimators=100, n_jobs=1, nthread=None,\n",
              "              objective='binary:logistic', predictor='gpu_predictor',\n",
              "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "              seed=None, silent=None, subsample=1, tree_method='gpu_hist',\n",
              "              use_label_encoder=False, verbosity=1)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHvsCNogew4d",
        "outputId": "38da2f20-1bf8-492e-c0a0-0db4b4ac636b"
      },
      "source": [
        "sample_submission['isFraud'] = pred_xgb[:,1]\r\n",
        "sample_submission.to_csv('/content/drive/MyDrive/kaggle/ieee/xgboost_bo.csv')\r\n",
        "!kaggle competitions submit -c ieee-fraud-detection -f /content/drive/MyDrive/kaggle/ieee/xgboost_bo.csv -m \"Message\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "100% 9.78M/9.78M [00:00<00:00, 24.7MB/s]\n",
            "Successfully submitted to IEEE-CIS Fraud Detection"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}